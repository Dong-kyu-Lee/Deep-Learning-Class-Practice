{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 3\n",
        "- 2020151035 이동규"
      ],
      "metadata": {
        "id": "ocJTVgZ_lz4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7u2lH-BlnAj"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "wandb.api.viewer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrDokbOnkmwi",
        "outputId": "73874883-03c1-40b7-d12e-25e6e1374007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.44.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstvboy00\u001b[0m (\u001b[33mstvboy00-korea-university-of-technology-and-education\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "!pip install wandb\n",
        "!pip install torchinfo\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PziYguewea52"
      },
      "source": [
        "# 문제 1\n",
        "- 아래 셀의 출력 결과로 fashion mnist data와 fashion mnist test data의 평균, 분산 값을 구하였다.\n",
        "- `fashion_mnist_train_data.py`에 계산 결과가 적용된 데이터 반환 함수가 구현되어 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "sjrALR_yW8Jx",
        "outputId": "13e420a3-6a98-4ec3-e3db-46981c9ad916"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/\n",
            "Num Train Samples:  55000\n",
            "Num Validation Samples:  5000\n",
            "Sample Data Shape:  torch.Size([1, 28, 28])\n",
            "Sample Data Target:  8\n",
            "Number of Data Loading Workers: 2\n",
            "\n",
            "Calculating mean and std for normalization...\n",
            "Calculated Mean: 0.28600025177001953\n",
            "Calculated Std: 0.3530220687389374\n",
            "\n",
            "Num Test Samples:  10000\n",
            "Sample Shape:  torch.Size([1, 28, 28])\n",
            "Calculated Mean: 0.2868492603302002\n",
            "Calculated Std: 0.3524441719055176\n"
          ]
        }
      ],
      "source": [
        "# train data의 mean, std와 test data의 mean, std를 구하기 위한 python 코드 실행\n",
        "%run fashion_mnist_train_data_1.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd5D9kvleToU"
      },
      "source": [
        "# 문제 2\n",
        "- 위에서 구한 mean과 std 값을 적용 (`fashion_mnist_train_data.py`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lqwpZrql9wV"
      },
      "source": [
        "## no normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lx67nux2eX1c",
        "outputId": "d8404066-ca6c-494b-8bbf-c9dd13005273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/checkpoint\n",
            "/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251118_094422-t2512wyk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/t2512wyk' target=\"_blank\">no_normalization_2025-11-18_09-44-22</a></strong> to <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/t2512wyk' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/t2512wyk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(wandb=True, batch_size=1024, epochs=50, learning_rate=0.001, validation_intervals=1, early_stop_patience=10, early_stop_delta=1e-05, optimizer=3, weight_decay=0.001, dropout=True, normalization=0, augment=False)\n",
            "{'epochs': 50, 'batch_size': 1024, 'validation_intervals': 1, 'learning_rate': 0.001, 'early_stop_patience': 10, 'early_stop_delta': 1e-05, 'weight_decay': 0.001, 'dropout': True, 'normalization': 0}\n",
            "Training on device cuda:0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:00<00:00, 114MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 3.75MB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 57.0MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 9.56MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train Samples:  55000\n",
            "Num Validation Samples:  5000\n",
            "Sample Data Shape:  torch.Size([1, 28, 28])\n",
            "Sample Data Target:  5\n",
            "Number of Data Loading Workers: 2\n",
            "================================================================================\n",
            "Model Structure (Normalization: 0)\n",
            "============================================================================================================================================\n",
            "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
            "============================================================================================================================================\n",
            "MyModel                                  [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "├─Sequential: 1-1                        [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "│    └─Conv2d: 2-1                       [1024, 1, 28, 28]         [1024, 16, 28, 28]        160                       128,450,560\n",
            "│    └─BatchNorm2d: 2-2                  [1024, 16, 28, 28]        [1024, 16, 28, 28]        32                        32,768\n",
            "│    └─ReLU: 2-3                         [1024, 16, 28, 28]        [1024, 16, 28, 28]        --                        --\n",
            "│    └─Conv2d: 2-4                       [1024, 16, 28, 28]        [1024, 64, 28, 28]        9,280                     7,450,132,480\n",
            "│    └─ReLU: 2-5                         [1024, 64, 28, 28]        [1024, 64, 28, 28]        --                        --\n",
            "│    └─MaxPool2d: 2-6                    [1024, 64, 28, 28]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Dropout: 2-7                      [1024, 64, 14, 14]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Conv2d: 2-8                       [1024, 64, 14, 14]        [1024, 128, 14, 14]       73,856                    14,823,194,624\n",
            "│    └─ReLU: 2-9                         [1024, 128, 14, 14]       [1024, 128, 14, 14]       --                        --\n",
            "│    └─MaxPool2d: 2-10                   [1024, 128, 14, 14]       [1024, 128, 7, 7]         --                        --\n",
            "│    └─Dropout: 2-11                     [1024, 128, 7, 7]         [1024, 128, 7, 7]         --                        --\n",
            "│    └─Flatten: 2-12                     [1024, 128, 7, 7]         [1024, 6272]              --                        --\n",
            "│    └─Dropout: 2-13                     [1024, 6272]              [1024, 6272]              --                        --\n",
            "│    └─Linear: 2-14                      [1024, 6272]              [1024, 128]               802,944                   822,214,656\n",
            "│    └─ReLU: 2-15                        [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Dropout: 2-16                     [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Linear: 2-17                      [1024, 128]               [1024, 10]                1,290                     1,320,960\n",
            "============================================================================================================================================\n",
            "Total params: 887,562\n",
            "Trainable params: 887,562\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 23.23\n",
            "============================================================================================================================================\n",
            "Input size (MB): 3.21\n",
            "Forward/backward pass size (MB): 823.21\n",
            "Params size (MB): 3.55\n",
            "Estimated Total Size (MB): 829.98\n",
            "============================================================================================================================================\n",
            "================================================================================\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "[Epoch   1] T_loss: 0.80382, T_accuracy: 71.0145 | V_loss: 0.46909, V_accuracy: 82.4600 | Early stopping is stated! | T_time: 00:00:08, T_speed: 0.125\n",
            "[Epoch   2] T_loss: 0.45782, T_accuracy: 83.5764 | V_loss: 0.36166, V_accuracy: 86.4800 | V_loss decreased (0.46909 --> 0.36166). Saving model... | T_time: 00:00:14, T_speed: 0.143\n",
            "[Epoch   3] T_loss: 0.39512, T_accuracy: 85.6273 | V_loss: 0.32450, V_accuracy: 88.0800 | V_loss decreased (0.36166 --> 0.32450). Saving model... | T_time: 00:00:21, T_speed: 0.143\n",
            "[Epoch   4] T_loss: 0.36351, T_accuracy: 87.0055 | V_loss: 0.29557, V_accuracy: 89.3000 | V_loss decreased (0.32450 --> 0.29557). Saving model... | T_time: 00:00:28, T_speed: 0.143\n",
            "[Epoch   5] T_loss: 0.33601, T_accuracy: 87.8382 | V_loss: 0.28055, V_accuracy: 89.4600 | V_loss decreased (0.29557 --> 0.28055). Saving model... | T_time: 00:00:35, T_speed: 0.143\n",
            "[Epoch   6] T_loss: 0.31869, T_accuracy: 88.5327 | V_loss: 0.26520, V_accuracy: 90.7800 | V_loss decreased (0.28055 --> 0.26520). Saving model... | T_time: 00:00:42, T_speed: 0.143\n",
            "[Epoch   7] T_loss: 0.30409, T_accuracy: 88.9891 | V_loss: 0.26238, V_accuracy: 90.8400 | V_loss decreased (0.26520 --> 0.26238). Saving model... | T_time: 00:00:49, T_speed: 0.143\n",
            "[Epoch   8] T_loss: 0.29320, T_accuracy: 89.4945 | V_loss: 0.25318, V_accuracy: 91.1600 | V_loss decreased (0.26238 --> 0.25318). Saving model... | T_time: 00:00:55, T_speed: 0.145\n",
            "[Epoch   9] T_loss: 0.28159, T_accuracy: 89.7218 | V_loss: 0.24222, V_accuracy: 91.6400 | V_loss decreased (0.25318 --> 0.24222). Saving model... | T_time: 00:01:02, T_speed: 0.145\n",
            "[Epoch  10] T_loss: 0.27299, T_accuracy: 90.1036 | V_loss: 0.23377, V_accuracy: 91.3800 | V_loss decreased (0.24222 --> 0.23377). Saving model... | T_time: 00:01:09, T_speed: 0.145\n",
            "[Epoch  11] T_loss: 0.26762, T_accuracy: 90.2055 | V_loss: 0.22960, V_accuracy: 91.9600 | V_loss decreased (0.23377 --> 0.22960). Saving model... | T_time: 00:01:16, T_speed: 0.145\n",
            "[Epoch  12] T_loss: 0.25730, T_accuracy: 90.7636 | V_loss: 0.23384, V_accuracy: 91.7000 | Early stopping counter: 1 out of 10 | T_time: 00:01:22, T_speed: 0.146\n",
            "[Epoch  13] T_loss: 0.25616, T_accuracy: 90.8364 | V_loss: 0.22231, V_accuracy: 92.1200 | V_loss decreased (0.22960 --> 0.22231). Saving model... | T_time: 00:01:29, T_speed: 0.146\n",
            "[Epoch  14] T_loss: 0.25481, T_accuracy: 90.8255 | V_loss: 0.22588, V_accuracy: 91.7800 | Early stopping counter: 1 out of 10 | T_time: 00:01:36, T_speed: 0.146\n",
            "[Epoch  15] T_loss: 0.25061, T_accuracy: 90.8873 | V_loss: 0.22470, V_accuracy: 91.8000 | Early stopping counter: 2 out of 10 | T_time: 00:01:43, T_speed: 0.146\n",
            "[Epoch  16] T_loss: 0.24446, T_accuracy: 91.0709 | V_loss: 0.21978, V_accuracy: 92.2600 | V_loss decreased (0.22231 --> 0.21978). Saving model... | T_time: 00:01:50, T_speed: 0.145\n",
            "[Epoch  17] T_loss: 0.23912, T_accuracy: 91.2800 | V_loss: 0.21514, V_accuracy: 92.3400 | V_loss decreased (0.21978 --> 0.21514). Saving model... | T_time: 00:01:57, T_speed: 0.145\n",
            "[Epoch  18] T_loss: 0.23731, T_accuracy: 91.3655 | V_loss: 0.21927, V_accuracy: 91.9400 | Early stopping counter: 1 out of 10 | T_time: 00:02:04, T_speed: 0.145\n",
            "[Epoch  19] T_loss: 0.23535, T_accuracy: 91.4909 | V_loss: 0.21223, V_accuracy: 92.3000 | V_loss decreased (0.21514 --> 0.21223). Saving model... | T_time: 00:02:11, T_speed: 0.145\n",
            "[Epoch  20] T_loss: 0.23168, T_accuracy: 91.4673 | V_loss: 0.21114, V_accuracy: 92.5200 | V_loss decreased (0.21223 --> 0.21114). Saving model... | T_time: 00:02:19, T_speed: 0.144\n",
            "[Epoch  21] T_loss: 0.23108, T_accuracy: 91.7945 | V_loss: 0.21723, V_accuracy: 92.3600 | Early stopping counter: 1 out of 10 | T_time: 00:02:25, T_speed: 0.145\n",
            "[Epoch  22] T_loss: 0.22494, T_accuracy: 91.9582 | V_loss: 0.20937, V_accuracy: 92.8200 | V_loss decreased (0.21114 --> 0.20937). Saving model... | T_time: 00:02:33, T_speed: 0.144\n",
            "[Epoch  23] T_loss: 0.22899, T_accuracy: 91.6764 | V_loss: 0.20513, V_accuracy: 92.5200 | V_loss decreased (0.20937 --> 0.20513). Saving model... | T_time: 00:02:39, T_speed: 0.145\n",
            "[Epoch  24] T_loss: 0.22485, T_accuracy: 91.8945 | V_loss: 0.20645, V_accuracy: 92.6200 | Early stopping counter: 1 out of 10 | T_time: 00:02:47, T_speed: 0.144\n",
            "[Epoch  25] T_loss: 0.22247, T_accuracy: 92.0345 | V_loss: 0.21626, V_accuracy: 92.1400 | Early stopping counter: 2 out of 10 | T_time: 00:02:53, T_speed: 0.145\n",
            "[Epoch  26] T_loss: 0.22357, T_accuracy: 92.0564 | V_loss: 0.20119, V_accuracy: 92.6800 | V_loss decreased (0.20513 --> 0.20119). Saving model... | T_time: 00:03:01, T_speed: 0.144\n",
            "[Epoch  27] T_loss: 0.21649, T_accuracy: 92.0382 | V_loss: 0.19842, V_accuracy: 92.4000 | V_loss decreased (0.20119 --> 0.19842). Saving model... | T_time: 00:03:08, T_speed: 0.144\n",
            "[Epoch  28] T_loss: 0.21553, T_accuracy: 92.2073 | V_loss: 0.20930, V_accuracy: 92.3600 | Early stopping counter: 1 out of 10 | T_time: 00:03:16, T_speed: 0.143\n",
            "[Epoch  29] T_loss: 0.21582, T_accuracy: 92.1200 | V_loss: 0.19934, V_accuracy: 92.7800 | Early stopping counter: 2 out of 10 | T_time: 00:03:22, T_speed: 0.144\n",
            "[Epoch  30] T_loss: 0.21575, T_accuracy: 92.1964 | V_loss: 0.19784, V_accuracy: 92.8400 | V_loss decreased (0.19842 --> 0.19784). Saving model... | T_time: 00:03:30, T_speed: 0.143\n",
            "[Epoch  31] T_loss: 0.21109, T_accuracy: 92.3982 | V_loss: 0.19477, V_accuracy: 92.8200 | V_loss decreased (0.19784 --> 0.19477). Saving model... | T_time: 00:03:36, T_speed: 0.144\n",
            "[Epoch  32] T_loss: 0.20934, T_accuracy: 92.4545 | V_loss: 0.19304, V_accuracy: 93.1600 | V_loss decreased (0.19477 --> 0.19304). Saving model... | T_time: 00:03:44, T_speed: 0.143\n",
            "[Epoch  33] T_loss: 0.21145, T_accuracy: 92.4545 | V_loss: 0.19448, V_accuracy: 93.0000 | Early stopping counter: 1 out of 10 | T_time: 00:03:51, T_speed: 0.143\n",
            "[Epoch  34] T_loss: 0.21316, T_accuracy: 92.1782 | V_loss: 0.19426, V_accuracy: 92.9000 | Early stopping counter: 2 out of 10 | T_time: 00:03:58, T_speed: 0.143\n",
            "[Epoch  35] T_loss: 0.20775, T_accuracy: 92.3073 | V_loss: 0.19289, V_accuracy: 93.1600 | V_loss decreased (0.19304 --> 0.19289). Saving model... | T_time: 00:04:05, T_speed: 0.143\n",
            "[Epoch  36] T_loss: 0.20839, T_accuracy: 92.4909 | V_loss: 0.19695, V_accuracy: 92.8800 | Early stopping counter: 1 out of 10 | T_time: 00:04:13, T_speed: 0.142\n",
            "[Epoch  37] T_loss: 0.20867, T_accuracy: 92.6145 | V_loss: 0.19565, V_accuracy: 92.6400 | Early stopping counter: 2 out of 10 | T_time: 00:04:20, T_speed: 0.142\n",
            "[Epoch  38] T_loss: 0.20506, T_accuracy: 92.6055 | V_loss: 0.19135, V_accuracy: 92.7600 | V_loss decreased (0.19289 --> 0.19135). Saving model... | T_time: 00:04:27, T_speed: 0.142\n",
            "[Epoch  39] T_loss: 0.20491, T_accuracy: 92.6873 | V_loss: 0.18945, V_accuracy: 93.1800 | V_loss decreased (0.19135 --> 0.18945). Saving model... | T_time: 00:04:35, T_speed: 0.142\n",
            "[Epoch  40] T_loss: 0.20408, T_accuracy: 92.5836 | V_loss: 0.19163, V_accuracy: 93.1800 | Early stopping counter: 1 out of 10 | T_time: 00:04:42, T_speed: 0.142\n",
            "[Epoch  41] T_loss: 0.20325, T_accuracy: 92.6509 | V_loss: 0.19133, V_accuracy: 93.0200 | Early stopping counter: 2 out of 10 | T_time: 00:04:49, T_speed: 0.142\n",
            "[Epoch  42] T_loss: 0.20193, T_accuracy: 92.7727 | V_loss: 0.18970, V_accuracy: 93.2000 | Early stopping counter: 3 out of 10 | T_time: 00:04:56, T_speed: 0.142\n",
            "[Epoch  43] T_loss: 0.20631, T_accuracy: 92.6164 | V_loss: 0.19297, V_accuracy: 93.0000 | Early stopping counter: 4 out of 10 | T_time: 00:05:04, T_speed: 0.141\n",
            "[Epoch  44] T_loss: 0.20265, T_accuracy: 92.6127 | V_loss: 0.18778, V_accuracy: 93.0400 | V_loss decreased (0.18945 --> 0.18778). Saving model... | T_time: 00:05:11, T_speed: 0.141\n",
            "[Epoch  45] T_loss: 0.19794, T_accuracy: 92.8600 | V_loss: 0.19109, V_accuracy: 92.8400 | Early stopping counter: 1 out of 10 | T_time: 00:05:19, T_speed: 0.141\n",
            "[Epoch  46] T_loss: 0.19939, T_accuracy: 92.8873 | V_loss: 0.18841, V_accuracy: 93.1200 | Early stopping counter: 2 out of 10 | T_time: 00:05:25, T_speed: 0.142\n",
            "[Epoch  47] T_loss: 0.20240, T_accuracy: 92.6909 | V_loss: 0.19241, V_accuracy: 92.9200 | Early stopping counter: 3 out of 10 | T_time: 00:05:33, T_speed: 0.141\n",
            "[Epoch  48] T_loss: 0.19886, T_accuracy: 92.8364 | V_loss: 0.18556, V_accuracy: 93.1200 | V_loss decreased (0.18778 --> 0.18556). Saving model... | T_time: 00:05:40, T_speed: 0.141\n",
            "[Epoch  49] T_loss: 0.19794, T_accuracy: 92.8036 | V_loss: 0.18922, V_accuracy: 92.9400 | Early stopping counter: 1 out of 10 | T_time: 00:05:48, T_speed: 0.141\n",
            "[Epoch  50] T_loss: 0.19546, T_accuracy: 92.8182 | V_loss: 0.18842, V_accuracy: 93.2000 | Early stopping counter: 2 out of 10 | T_time: 00:05:55, T_speed: 0.141\n",
            "Final training time: 00:05:55\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Training accuracy (%)</td><td>▁▃▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇██▇█████████████</td></tr><tr><td>Training loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▁▇▇▇▇███████████▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆</td></tr><tr><td>Validation accuracy (%)</td><td>▁▄▅▅▆▆▇▇▇▇▇▇▇▇▇█▇████▇▇█████████████████</td></tr><tr><td>Validation loss</td><td>█▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>50</td></tr><tr><td>Training accuracy (%)</td><td>92.81818</td></tr><tr><td>Training loss</td><td>0.19546</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.14085</td></tr><tr><td>Validation accuracy (%)</td><td>93.2</td></tr><tr><td>Validation loss</td><td>0.18842</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">no_normalization_2025-11-18_09-44-22</strong> at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/t2512wyk' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/t2512wyk</a><br> View project at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251118_094422-t2512wyk/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%run fashion_mnist_train_cnn_with_norm.py --wandb -b 1024 -v 1 -o 3 -w 0.001 --dropout -n 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiIEnrUPjWDl"
      },
      "source": [
        "## batch normalization\n",
        "\n",
        "### 내가 선택한 최적의 하이퍼 파라미터\n",
        "- batch_size=1024\n",
        "- epochs=50\n",
        "- learning_rate=0.001\n",
        "- validation_intervals=1\n",
        "- early_stop_patience=6\n",
        "- early_stop_delta=1e-0\n",
        "- optimizer = Adam\n",
        "- weight_decay=0.001\n",
        "- dropout=True\n",
        "- normalization=Batch norm\n",
        "- augment=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M5nJt2XcpCtJ",
        "outputId": "7a3cc789-8d62-4588-8d5d-4dbf96fbebfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/checkpoint\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251118_095102-0ct4oyzz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/0ct4oyzz' target=\"_blank\">batch_norm_2025-11-18_09-51-02</a></strong> to <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/0ct4oyzz' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/0ct4oyzz</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(wandb=True, batch_size=1024, epochs=50, learning_rate=0.001, validation_intervals=1, early_stop_patience=10, early_stop_delta=1e-05, optimizer=3, weight_decay=0.001, dropout=True, normalization=1, augment=False)\n",
            "{'epochs': 50, 'batch_size': 1024, 'validation_intervals': 1, 'learning_rate': 0.001, 'early_stop_patience': 10, 'early_stop_delta': 1e-05, 'weight_decay': 0.001, 'dropout': True, 'normalization': 1}\n",
            "Training on device cuda:0.\n",
            "Num Train Samples:  55000\n",
            "Num Validation Samples:  5000\n",
            "Sample Data Shape:  torch.Size([1, 28, 28])\n",
            "Sample Data Target:  7\n",
            "Number of Data Loading Workers: 2\n",
            "================================================================================\n",
            "Model Structure (Normalization: 1)\n",
            "============================================================================================================================================\n",
            "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
            "============================================================================================================================================\n",
            "MyModel                                  [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "├─Sequential: 1-1                        [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "│    └─Conv2d: 2-1                       [1024, 1, 28, 28]         [1024, 16, 28, 28]        160                       128,450,560\n",
            "│    └─BatchNorm2d: 2-2                  [1024, 16, 28, 28]        [1024, 16, 28, 28]        32                        32,768\n",
            "│    └─ReLU: 2-3                         [1024, 16, 28, 28]        [1024, 16, 28, 28]        --                        --\n",
            "│    └─Conv2d: 2-4                       [1024, 16, 28, 28]        [1024, 64, 28, 28]        9,280                     7,450,132,480\n",
            "│    └─BatchNorm2d: 2-5                  [1024, 64, 28, 28]        [1024, 64, 28, 28]        128                       131,072\n",
            "│    └─ReLU: 2-6                         [1024, 64, 28, 28]        [1024, 64, 28, 28]        --                        --\n",
            "│    └─MaxPool2d: 2-7                    [1024, 64, 28, 28]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Dropout: 2-8                      [1024, 64, 14, 14]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Conv2d: 2-9                       [1024, 64, 14, 14]        [1024, 128, 14, 14]       73,856                    14,823,194,624\n",
            "│    └─BatchNorm2d: 2-10                 [1024, 128, 14, 14]       [1024, 128, 14, 14]       256                       262,144\n",
            "│    └─ReLU: 2-11                        [1024, 128, 14, 14]       [1024, 128, 14, 14]       --                        --\n",
            "│    └─MaxPool2d: 2-12                   [1024, 128, 14, 14]       [1024, 128, 7, 7]         --                        --\n",
            "│    └─Dropout: 2-13                     [1024, 128, 7, 7]         [1024, 128, 7, 7]         --                        --\n",
            "│    └─Flatten: 2-14                     [1024, 128, 7, 7]         [1024, 6272]              --                        --\n",
            "│    └─Dropout: 2-15                     [1024, 6272]              [1024, 6272]              --                        --\n",
            "│    └─Linear: 2-16                      [1024, 6272]              [1024, 128]               802,944                   822,214,656\n",
            "│    └─BatchNorm1d: 2-17                 [1024, 128]               [1024, 128]               256                       262,144\n",
            "│    └─ReLU: 2-18                        [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Dropout: 2-19                     [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Linear: 2-20                      [1024, 128]               [1024, 10]                1,290                     1,320,960\n",
            "============================================================================================================================================\n",
            "Total params: 888,202\n",
            "Trainable params: 888,202\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 23.23\n",
            "============================================================================================================================================\n",
            "Input size (MB): 3.21\n",
            "Forward/backward pass size (MB): 1440.83\n",
            "Params size (MB): 3.55\n",
            "Estimated Total Size (MB): 1447.59\n",
            "============================================================================================================================================\n",
            "================================================================================\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "[Epoch   1] T_loss: 0.76390, T_accuracy: 76.1400 | V_loss: 0.42435, V_accuracy: 86.1200 | Early stopping is stated! | T_time: 00:00:08, T_speed: 0.125\n",
            "[Epoch   2] T_loss: 0.43128, T_accuracy: 85.4891 | V_loss: 0.30748, V_accuracy: 89.4800 | V_loss decreased (0.42435 --> 0.30748). Saving model... | T_time: 00:00:15, T_speed: 0.133\n",
            "[Epoch   3] T_loss: 0.36327, T_accuracy: 87.7091 | V_loss: 0.26662, V_accuracy: 90.6800 | V_loss decreased (0.30748 --> 0.26662). Saving model... | T_time: 00:00:23, T_speed: 0.130\n",
            "[Epoch   4] T_loss: 0.33333, T_accuracy: 88.3418 | V_loss: 0.25091, V_accuracy: 91.4000 | V_loss decreased (0.26662 --> 0.25091). Saving model... | T_time: 00:00:30, T_speed: 0.133\n",
            "[Epoch   5] T_loss: 0.30957, T_accuracy: 89.4091 | V_loss: 0.23416, V_accuracy: 91.6800 | V_loss decreased (0.25091 --> 0.23416). Saving model... | T_time: 00:00:42, T_speed: 0.119\n",
            "[Epoch   6] T_loss: 0.29470, T_accuracy: 89.7764 | V_loss: 0.23010, V_accuracy: 92.0800 | V_loss decreased (0.23416 --> 0.23010). Saving model... | T_time: 00:00:50, T_speed: 0.120\n",
            "[Epoch   7] T_loss: 0.28203, T_accuracy: 90.1218 | V_loss: 0.23067, V_accuracy: 91.7000 | Early stopping counter: 1 out of 10 | T_time: 00:00:57, T_speed: 0.123\n",
            "[Epoch   8] T_loss: 0.27425, T_accuracy: 90.4455 | V_loss: 0.21532, V_accuracy: 92.6200 | V_loss decreased (0.23010 --> 0.21532). Saving model... | T_time: 00:01:05, T_speed: 0.123\n",
            "[Epoch   9] T_loss: 0.26652, T_accuracy: 90.7055 | V_loss: 0.21330, V_accuracy: 92.3600 | V_loss decreased (0.21532 --> 0.21330). Saving model... | T_time: 00:01:12, T_speed: 0.125\n",
            "[Epoch  10] T_loss: 0.25721, T_accuracy: 90.9400 | V_loss: 0.20457, V_accuracy: 92.7200 | V_loss decreased (0.21330 --> 0.20457). Saving model... | T_time: 00:01:20, T_speed: 0.125\n",
            "[Epoch  11] T_loss: 0.24724, T_accuracy: 91.5109 | V_loss: 0.20253, V_accuracy: 92.7600 | V_loss decreased (0.20457 --> 0.20253). Saving model... | T_time: 00:01:28, T_speed: 0.125\n",
            "[Epoch  12] T_loss: 0.24625, T_accuracy: 91.4709 | V_loss: 0.19789, V_accuracy: 92.9600 | V_loss decreased (0.20253 --> 0.19789). Saving model... | T_time: 00:01:36, T_speed: 0.125\n",
            "[Epoch  13] T_loss: 0.24157, T_accuracy: 91.5927 | V_loss: 0.19644, V_accuracy: 92.7600 | V_loss decreased (0.19789 --> 0.19644). Saving model... | T_time: 00:01:43, T_speed: 0.126\n",
            "[Epoch  14] T_loss: 0.23537, T_accuracy: 91.9545 | V_loss: 0.19045, V_accuracy: 93.1400 | V_loss decreased (0.19644 --> 0.19045). Saving model... | T_time: 00:01:51, T_speed: 0.126\n",
            "[Epoch  15] T_loss: 0.23043, T_accuracy: 91.9782 | V_loss: 0.19671, V_accuracy: 92.7400 | Early stopping counter: 1 out of 10 | T_time: 00:02:00, T_speed: 0.125\n",
            "[Epoch  16] T_loss: 0.22802, T_accuracy: 91.9964 | V_loss: 0.19638, V_accuracy: 92.9600 | Early stopping counter: 2 out of 10 | T_time: 00:02:08, T_speed: 0.125\n",
            "[Epoch  17] T_loss: 0.22622, T_accuracy: 92.2564 | V_loss: 0.18599, V_accuracy: 93.5200 | V_loss decreased (0.19045 --> 0.18599). Saving model... | T_time: 00:02:17, T_speed: 0.124\n",
            "[Epoch  18] T_loss: 0.21926, T_accuracy: 92.4436 | V_loss: 0.18828, V_accuracy: 93.0200 | Early stopping counter: 1 out of 10 | T_time: 00:02:24, T_speed: 0.125\n",
            "[Epoch  19] T_loss: 0.21615, T_accuracy: 92.4164 | V_loss: 0.19145, V_accuracy: 93.1400 | Early stopping counter: 2 out of 10 | T_time: 00:02:32, T_speed: 0.125\n",
            "[Epoch  20] T_loss: 0.21528, T_accuracy: 92.5345 | V_loss: 0.18286, V_accuracy: 93.5400 | V_loss decreased (0.18599 --> 0.18286). Saving model... | T_time: 00:02:40, T_speed: 0.125\n",
            "[Epoch  21] T_loss: 0.20920, T_accuracy: 92.7836 | V_loss: 0.18215, V_accuracy: 93.2200 | V_loss decreased (0.18286 --> 0.18215). Saving model... | T_time: 00:02:47, T_speed: 0.126\n",
            "[Epoch  22] T_loss: 0.21054, T_accuracy: 92.7309 | V_loss: 0.18770, V_accuracy: 93.0200 | Early stopping counter: 1 out of 10 | T_time: 00:02:55, T_speed: 0.126\n",
            "[Epoch  23] T_loss: 0.20937, T_accuracy: 92.7255 | V_loss: 0.17817, V_accuracy: 93.4400 | V_loss decreased (0.18215 --> 0.17817). Saving model... | T_time: 00:03:02, T_speed: 0.126\n",
            "[Epoch  24] T_loss: 0.20460, T_accuracy: 92.7673 | V_loss: 0.17506, V_accuracy: 93.3800 | V_loss decreased (0.17817 --> 0.17506). Saving model... | T_time: 00:03:10, T_speed: 0.126\n",
            "[Epoch  25] T_loss: 0.20405, T_accuracy: 92.9145 | V_loss: 0.17400, V_accuracy: 93.5800 | V_loss decreased (0.17506 --> 0.17400). Saving model... | T_time: 00:03:18, T_speed: 0.126\n",
            "[Epoch  26] T_loss: 0.20024, T_accuracy: 93.1018 | V_loss: 0.17968, V_accuracy: 93.6400 | Early stopping counter: 1 out of 10 | T_time: 00:03:26, T_speed: 0.126\n",
            "[Epoch  27] T_loss: 0.19758, T_accuracy: 93.1291 | V_loss: 0.17165, V_accuracy: 93.6200 | V_loss decreased (0.17400 --> 0.17165). Saving model... | T_time: 00:03:34, T_speed: 0.126\n",
            "[Epoch  28] T_loss: 0.19768, T_accuracy: 93.2782 | V_loss: 0.17609, V_accuracy: 93.5600 | Early stopping counter: 1 out of 10 | T_time: 00:03:42, T_speed: 0.126\n",
            "[Epoch  29] T_loss: 0.19273, T_accuracy: 93.3073 | V_loss: 0.17162, V_accuracy: 93.6200 | V_loss decreased (0.17165 --> 0.17162). Saving model... | T_time: 00:03:50, T_speed: 0.126\n",
            "[Epoch  30] T_loss: 0.19389, T_accuracy: 93.2818 | V_loss: 0.17266, V_accuracy: 93.4000 | Early stopping counter: 1 out of 10 | T_time: 00:03:57, T_speed: 0.127\n",
            "[Epoch  31] T_loss: 0.19224, T_accuracy: 93.4182 | V_loss: 0.17363, V_accuracy: 93.4200 | Early stopping counter: 2 out of 10 | T_time: 00:04:05, T_speed: 0.127\n",
            "[Epoch  32] T_loss: 0.19168, T_accuracy: 93.3473 | V_loss: 0.17113, V_accuracy: 93.6600 | V_loss decreased (0.17162 --> 0.17113). Saving model... | T_time: 00:04:12, T_speed: 0.127\n",
            "[Epoch  33] T_loss: 0.19068, T_accuracy: 93.3873 | V_loss: 0.17861, V_accuracy: 93.8000 | Early stopping counter: 1 out of 10 | T_time: 00:04:20, T_speed: 0.127\n",
            "[Epoch  34] T_loss: 0.18782, T_accuracy: 93.4909 | V_loss: 0.17403, V_accuracy: 93.6000 | Early stopping counter: 2 out of 10 | T_time: 00:04:28, T_speed: 0.127\n",
            "[Epoch  35] T_loss: 0.18770, T_accuracy: 93.4655 | V_loss: 0.17197, V_accuracy: 93.5600 | Early stopping counter: 3 out of 10 | T_time: 00:04:35, T_speed: 0.127\n",
            "[Epoch  36] T_loss: 0.18625, T_accuracy: 93.4545 | V_loss: 0.16971, V_accuracy: 93.6800 | V_loss decreased (0.17113 --> 0.16971). Saving model... | T_time: 00:04:43, T_speed: 0.127\n",
            "[Epoch  37] T_loss: 0.18667, T_accuracy: 93.5145 | V_loss: 0.17665, V_accuracy: 93.3200 | Early stopping counter: 1 out of 10 | T_time: 00:04:50, T_speed: 0.128\n",
            "[Epoch  38] T_loss: 0.18272, T_accuracy: 93.5800 | V_loss: 0.17487, V_accuracy: 93.4400 | Early stopping counter: 2 out of 10 | T_time: 00:04:58, T_speed: 0.128\n",
            "[Epoch  39] T_loss: 0.18249, T_accuracy: 93.6927 | V_loss: 0.17007, V_accuracy: 93.8400 | Early stopping counter: 3 out of 10 | T_time: 00:05:05, T_speed: 0.128\n",
            "[Epoch  40] T_loss: 0.18324, T_accuracy: 93.5873 | V_loss: 0.17218, V_accuracy: 93.5000 | Early stopping counter: 4 out of 10 | T_time: 00:05:13, T_speed: 0.128\n",
            "[Epoch  41] T_loss: 0.18130, T_accuracy: 93.6909 | V_loss: 0.17133, V_accuracy: 93.7400 | Early stopping counter: 5 out of 10 | T_time: 00:05:20, T_speed: 0.128\n",
            "[Epoch  42] T_loss: 0.18027, T_accuracy: 93.7636 | V_loss: 0.16256, V_accuracy: 93.7200 | V_loss decreased (0.16971 --> 0.16256). Saving model... | T_time: 00:05:28, T_speed: 0.128\n",
            "[Epoch  43] T_loss: 0.17829, T_accuracy: 93.8709 | V_loss: 0.16640, V_accuracy: 93.9000 | Early stopping counter: 1 out of 10 | T_time: 00:05:36, T_speed: 0.128\n",
            "[Epoch  44] T_loss: 0.17675, T_accuracy: 93.8891 | V_loss: 0.16777, V_accuracy: 93.9200 | Early stopping counter: 2 out of 10 | T_time: 00:05:43, T_speed: 0.128\n",
            "[Epoch  45] T_loss: 0.17715, T_accuracy: 93.8582 | V_loss: 0.17121, V_accuracy: 93.6200 | Early stopping counter: 3 out of 10 | T_time: 00:05:51, T_speed: 0.128\n",
            "[Epoch  46] T_loss: 0.17270, T_accuracy: 94.0400 | V_loss: 0.16992, V_accuracy: 93.7600 | Early stopping counter: 4 out of 10 | T_time: 00:05:58, T_speed: 0.128\n",
            "[Epoch  47] T_loss: 0.17637, T_accuracy: 93.8473 | V_loss: 0.16535, V_accuracy: 93.8200 | Early stopping counter: 5 out of 10 | T_time: 00:06:06, T_speed: 0.128\n",
            "[Epoch  48] T_loss: 0.17539, T_accuracy: 93.9491 | V_loss: 0.16475, V_accuracy: 94.1000 | Early stopping counter: 6 out of 10 | T_time: 00:06:13, T_speed: 0.129\n",
            "[Epoch  49] T_loss: 0.17498, T_accuracy: 93.9236 | V_loss: 0.17771, V_accuracy: 93.3000 | Early stopping counter: 7 out of 10 | T_time: 00:06:21, T_speed: 0.129\n",
            "[Epoch  50] T_loss: 0.17661, T_accuracy: 93.8855 | V_loss: 0.16829, V_accuracy: 94.0200 | Early stopping counter: 8 out of 10 | T_time: 00:06:28, T_speed: 0.129\n",
            "Final training time: 00:06:28\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Training accuracy (%)</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇█▇▇█████████████████████</td></tr><tr><td>Training loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>▄█▇█▁▃▃▄▄▄▄▄▄▃▄▄▄▄▅▅▅▄▄▄▅▅▅▅▅▅▅▅▅▅▅▆▅▆▆▆</td></tr><tr><td>Validation accuracy (%)</td><td>▁▄▅▆▆▆▇▆▇▇▇▇▇▇▇▇█▇▇▇██████████▇█████████</td></tr><tr><td>Validation loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>50</td></tr><tr><td>Training accuracy (%)</td><td>93.88545</td></tr><tr><td>Training loss</td><td>0.17661</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.12887</td></tr><tr><td>Validation accuracy (%)</td><td>94.02</td></tr><tr><td>Validation loss</td><td>0.16829</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_norm_2025-11-18_09-51-02</strong> at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/0ct4oyzz' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/0ct4oyzz</a><br> View project at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251118_095102-0ct4oyzz/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "%run fashion_mnist_train_cnn_with_norm.py --wandb -b 1024 -v 1 -o 3 -w 0.001 --dropout -n 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer normalization"
      ],
      "metadata": {
        "id": "2tHaFES9X1qp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run fashion_mnist_train_cnn_with_norm.py --wandb -b 1024 -v 1 -o 3 -w 0.001 --dropout -n 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NZ6OY-VwX1Gt",
        "outputId": "579208b4-9e0c-4b74-e549-23d279431d5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/checkpoint\n",
            "/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mstvboy00\u001b[0m (\u001b[33mstvboy00-korea-university-of-technology-and-education\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251115_165532-crkh8zk8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/crkh8zk8' target=\"_blank\">layer_norm_2025-11-15_16-55-29</a></strong> to <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/crkh8zk8' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/crkh8zk8</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(wandb=True, batch_size=1024, epochs=50, learning_rate=0.001, validation_intervals=1, early_stop_patience=6, early_stop_delta=1e-05, optimizer=3, weight_decay=0.001, dropout=True, normalization=2, augment=False)\n",
            "{'epochs': 50, 'batch_size': 1024, 'validation_intervals': 1, 'learning_rate': 0.001, 'early_stop_patience': 6, 'early_stop_delta': 1e-05, 'weight_decay': 0.001, 'dropout': True, 'normalization': 2}\n",
            "Training on device cuda:0.\n",
            "Num Train Samples:  55000\n",
            "Num Validation Samples:  5000\n",
            "Sample Data Shape:  torch.Size([1, 28, 28])\n",
            "Sample Data Target:  3\n",
            "Number of Data Loading Workers: 2\n",
            "================================================================================\n",
            "Model Structure (Normalization: 2)\n",
            "============================================================================================================================================\n",
            "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
            "============================================================================================================================================\n",
            "MyModel                                  [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "├─Sequential: 1-1                        [1024, 1, 28, 28]         [1024, 10]                --                        --\n",
            "│    └─Conv2d: 2-1                       [1024, 1, 28, 28]         [1024, 16, 28, 28]        160                       128,450,560\n",
            "│    └─LayerNorm: 2-2                    [1024, 16, 28, 28]        [1024, 16, 28, 28]        25,088                    25,690,112\n",
            "│    └─ReLU: 2-3                         [1024, 16, 28, 28]        [1024, 16, 28, 28]        --                        --\n",
            "│    └─Conv2d: 2-4                       [1024, 16, 28, 28]        [1024, 64, 28, 28]        9,280                     7,450,132,480\n",
            "│    └─LayerNorm: 2-5                    [1024, 64, 28, 28]        [1024, 64, 28, 28]        100,352                   102,760,448\n",
            "│    └─ReLU: 2-6                         [1024, 64, 28, 28]        [1024, 64, 28, 28]        --                        --\n",
            "│    └─MaxPool2d: 2-7                    [1024, 64, 28, 28]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Dropout: 2-8                      [1024, 64, 14, 14]        [1024, 64, 14, 14]        --                        --\n",
            "│    └─Conv2d: 2-9                       [1024, 64, 14, 14]        [1024, 128, 14, 14]       73,856                    14,823,194,624\n",
            "│    └─LayerNorm: 2-10                   [1024, 128, 14, 14]       [1024, 128, 14, 14]       50,176                    51,380,224\n",
            "│    └─ReLU: 2-11                        [1024, 128, 14, 14]       [1024, 128, 14, 14]       --                        --\n",
            "│    └─MaxPool2d: 2-12                   [1024, 128, 14, 14]       [1024, 128, 7, 7]         --                        --\n",
            "│    └─Dropout: 2-13                     [1024, 128, 7, 7]         [1024, 128, 7, 7]         --                        --\n",
            "│    └─Flatten: 2-14                     [1024, 128, 7, 7]         [1024, 6272]              --                        --\n",
            "│    └─Dropout: 2-15                     [1024, 6272]              [1024, 6272]              --                        --\n",
            "│    └─Linear: 2-16                      [1024, 6272]              [1024, 128]               802,944                   822,214,656\n",
            "│    └─LayerNorm: 2-17                   [1024, 128]               [1024, 128]               256                       262,144\n",
            "│    └─ReLU: 2-18                        [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Dropout: 2-19                     [1024, 128]               [1024, 128]               --                        --\n",
            "│    └─Linear: 2-20                      [1024, 128]               [1024, 10]                1,290                     1,320,960\n",
            "============================================================================================================================================\n",
            "Total params: 1,063,402\n",
            "Trainable params: 1,063,402\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.GIGABYTES): 23.41\n",
            "============================================================================================================================================\n",
            "Input size (MB): 3.21\n",
            "Forward/backward pass size (MB): 1440.83\n",
            "Params size (MB): 4.25\n",
            "Estimated Total Size (MB): 1448.29\n",
            "============================================================================================================================================\n",
            "================================================================================\n",
            "Optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    weight_decay: 0.001\n",
            ")\n",
            "[Epoch   1] T_loss: 0.99558, T_accuracy: 67.8127 | V_loss: 0.49675, V_accuracy: 82.5800 | Early stopping is stated! | T_time: 00:00:07, T_speed: 0.143\n",
            "[Epoch   2] T_loss: 0.49977, T_accuracy: 83.1727 | V_loss: 0.36561, V_accuracy: 87.3400 | V_loss decreased (0.49675 --> 0.36561). Saving model... | T_time: 00:00:14, T_speed: 0.143\n",
            "[Epoch   3] T_loss: 0.41984, T_accuracy: 85.5800 | V_loss: 0.32044, V_accuracy: 88.6600 | V_loss decreased (0.36561 --> 0.32044). Saving model... | T_time: 00:00:22, T_speed: 0.136\n",
            "[Epoch   4] T_loss: 0.37844, T_accuracy: 86.8927 | V_loss: 0.28733, V_accuracy: 89.8600 | V_loss decreased (0.32044 --> 0.28733). Saving model... | T_time: 00:00:29, T_speed: 0.138\n",
            "[Epoch   5] T_loss: 0.35498, T_accuracy: 87.6964 | V_loss: 0.26945, V_accuracy: 90.4800 | V_loss decreased (0.28733 --> 0.26945). Saving model... | T_time: 00:00:37, T_speed: 0.135\n",
            "[Epoch   6] T_loss: 0.33687, T_accuracy: 88.3800 | V_loss: 0.25166, V_accuracy: 91.0600 | V_loss decreased (0.26945 --> 0.25166). Saving model... | T_time: 00:00:44, T_speed: 0.136\n",
            "[Epoch   7] T_loss: 0.32425, T_accuracy: 88.6964 | V_loss: 0.24697, V_accuracy: 91.1000 | V_loss decreased (0.25166 --> 0.24697). Saving model... | T_time: 00:00:51, T_speed: 0.137\n",
            "[Epoch   8] T_loss: 0.31466, T_accuracy: 89.0527 | V_loss: 0.23873, V_accuracy: 91.6000 | V_loss decreased (0.24697 --> 0.23873). Saving model... | T_time: 00:00:58, T_speed: 0.138\n",
            "[Epoch   9] T_loss: 0.30103, T_accuracy: 89.4582 | V_loss: 0.22745, V_accuracy: 92.0000 | V_loss decreased (0.23873 --> 0.22745). Saving model... | T_time: 00:01:05, T_speed: 0.138\n",
            "[Epoch  10] T_loss: 0.29565, T_accuracy: 89.7345 | V_loss: 0.23112, V_accuracy: 92.0400 | Early stopping counter: 1 out of 6 | T_time: 00:01:13, T_speed: 0.137\n",
            "[Epoch  11] T_loss: 0.29295, T_accuracy: 89.7727 | V_loss: 0.22136, V_accuracy: 92.1200 | V_loss decreased (0.22745 --> 0.22136). Saving model... | T_time: 00:01:19, T_speed: 0.139\n",
            "[Epoch  12] T_loss: 0.28779, T_accuracy: 89.8709 | V_loss: 0.21428, V_accuracy: 92.5800 | V_loss decreased (0.22136 --> 0.21428). Saving model... | T_time: 00:01:27, T_speed: 0.138\n",
            "[Epoch  13] T_loss: 0.27823, T_accuracy: 90.2909 | V_loss: 0.21153, V_accuracy: 92.7400 | V_loss decreased (0.21428 --> 0.21153). Saving model... | T_time: 00:01:34, T_speed: 0.138\n",
            "[Epoch  14] T_loss: 0.27327, T_accuracy: 90.3291 | V_loss: 0.20896, V_accuracy: 92.7800 | V_loss decreased (0.21153 --> 0.20896). Saving model... | T_time: 00:01:41, T_speed: 0.139\n",
            "[Epoch  15] T_loss: 0.27513, T_accuracy: 90.2164 | V_loss: 0.20718, V_accuracy: 92.6400 | V_loss decreased (0.20896 --> 0.20718). Saving model... | T_time: 00:01:48, T_speed: 0.139\n",
            "[Epoch  16] T_loss: 0.26736, T_accuracy: 90.6109 | V_loss: 0.20947, V_accuracy: 92.9000 | Early stopping counter: 1 out of 6 | T_time: 00:01:55, T_speed: 0.139\n",
            "[Epoch  17] T_loss: 0.26708, T_accuracy: 90.6309 | V_loss: 0.21392, V_accuracy: 92.3800 | Early stopping counter: 2 out of 6 | T_time: 00:02:02, T_speed: 0.139\n",
            "[Epoch  18] T_loss: 0.25924, T_accuracy: 91.0164 | V_loss: 0.19746, V_accuracy: 93.4000 | V_loss decreased (0.20718 --> 0.19746). Saving model... | T_time: 00:02:09, T_speed: 0.140\n",
            "[Epoch  19] T_loss: 0.25789, T_accuracy: 90.8582 | V_loss: 0.20187, V_accuracy: 92.9600 | Early stopping counter: 1 out of 6 | T_time: 00:02:16, T_speed: 0.140\n",
            "[Epoch  20] T_loss: 0.25186, T_accuracy: 91.1400 | V_loss: 0.20043, V_accuracy: 93.4600 | Early stopping counter: 2 out of 6 | T_time: 00:02:23, T_speed: 0.140\n",
            "[Epoch  21] T_loss: 0.25156, T_accuracy: 91.2436 | V_loss: 0.19876, V_accuracy: 92.9000 | Early stopping counter: 3 out of 6 | T_time: 00:02:30, T_speed: 0.140\n",
            "[Epoch  22] T_loss: 0.24647, T_accuracy: 91.4927 | V_loss: 0.19834, V_accuracy: 93.3200 | Early stopping counter: 4 out of 6 | T_time: 00:02:37, T_speed: 0.140\n",
            "[Epoch  23] T_loss: 0.24743, T_accuracy: 91.3818 | V_loss: 0.20101, V_accuracy: 92.9200 | Early stopping counter: 5 out of 6 | T_time: 00:02:45, T_speed: 0.139\n",
            "[Epoch  24] T_loss: 0.24750, T_accuracy: 91.4345 | V_loss: 0.20978, V_accuracy: 92.5600 | Early stopping counter: 6 out of 6 *** TRAIN EARLY STOPPED! *** | T_time: 00:02:52, T_speed: 0.140\n",
            "Final training time: 00:02:52\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▅▅▅▆▆▆▆▇▇▇██</td></tr><tr><td>Training accuracy (%)</td><td>▁▆▆▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>Training loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Training speed (epochs/sec.)</td><td>██▂▄▁▂▃▄▄▃▅▄▄▄▄▅▅▅▅▅▅▆▅▅</td></tr><tr><td>Validation accuracy (%)</td><td>▁▄▅▆▆▆▆▇▇▇▇▇██▇█▇██████▇</td></tr><tr><td>Validation loss</td><td>█▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>24</td></tr><tr><td>Training accuracy (%)</td><td>91.43455</td></tr><tr><td>Training loss</td><td>0.2475</td></tr><tr><td>Training speed (epochs/sec.)</td><td>0.13953</td></tr><tr><td>Validation accuracy (%)</td><td>92.56</td></tr><tr><td>Validation loss</td><td>0.20978</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">layer_norm_2025-11-15_16-55-29</strong> at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/crkh8zk8' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization/runs/crkh8zk8</a><br> View project at: <a href='https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization' target=\"_blank\">https://wandb.ai/stvboy00-korea-university-of-technology-and-education/cnn_fashion_mnist_with_normalization</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251115_165532-crkh8zk8/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제 3\n",
        "- Test Accuracy : 93.4900%\n",
        "\n",
        "## 모델 (batch normalization 셀의 모델과 동일)\n",
        "- batch_size=1024\n",
        "- epochs=50\n",
        "- learning_rate=0.001\n",
        "- validation_intervals=1\n",
        "- early_stop_patience=6\n",
        "- early_stop_delta=1e-0\n",
        "- optimizer = Adam\n",
        "- weight_decay=0.001\n",
        "- dropout=True\n",
        "- normalization=Batch norm\n",
        "- augment=False"
      ],
      "metadata": {
        "id": "oW5-gWpLYXBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python fashion_mnist_test.py -n 1 -c cnn_fashion_mnist_with_normalization_checkpoint_2025-11-18_09-51-02.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmrY3JKwYXVF",
        "outputId": "386312e3-30ec-4b59-850a-a6f228483228"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Path: /content\n",
            "/\n",
            "/content\n",
            "/content/checkpoint\n",
            "Using device: cuda:0\n",
            "Num Test Samples:  10000\n",
            "Sample Shape:  torch.Size([1, 28, 28])\n",
            "Loaded 10000 test samples.\n",
            "Instantiated model structure with: Batch Normalization\n",
            "Successfully loaded trained weights from: cnn_fashion_mnist_with_normalization_checkpoint_2025-11-18_09-51-02.pt\n",
            "\n",
            "========================================\n",
            "  Model: Batch Normalization (cnn_fashion_mnist_with_normalization_checkpoint_2025-11-18_09-51-02.pt)\n",
            "  Test Accuracy: 93.4900%\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문제 4"
      ],
      "metadata": {
        "id": "4BZrMYK6i8RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run predict_sample.py -n 1 -c /content/checkpoint/cnn_fashion_mnist_with_normalization_checkpoint_2025-11-18_09-51-02.pt"
      ],
      "metadata": {
        "id": "V-oURvlEi87k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "6850f9d6-b77f-4ebb-d8dd-010e879f92e8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base Path: /content\n",
            "Using device: cuda:0\n",
            "Loading test data...\n",
            "Num Test Samples:  10000\n",
            "Sample Shape:  torch.Size([1, 28, 28])\n",
            "Loading model structure with: Batch Normalization\n",
            "Loading weights from /content/checkpoint/cnn_fashion_mnist_with_normalization_checkpoint_2025-11-18_09-51-02.pt...\n",
            "Running predictions on 10 random images...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x800 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 예측 결과가 틀린 이유 고찰\n",
        "- 목이 라운드하게 파여있는 셔츠와 티셔츠의 공통 특성과, 형태의 유사성 때문에 햇갈렸을 것이라고 추측된다."
      ],
      "metadata": {
        "id": "kk2QbkEFf-tn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Codes (실행 X)"
      ],
      "metadata": {
        "id": "33U_704Yi6Vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기\n",
        "- `fashion_mnist_train_data` : mean값과 std값을 찾기 전 데이터 로더 코드\n",
        "- `fashion_mnist_train_data_1` : 찾은 mean 값과 std 값을 적용한 데이터 로더 코드"
      ],
      "metadata": {
        "id": "vEQBTFnui_9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fashion_mnist_train_data.py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import wandb\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve().parent) # BASE_PATH: /Users/stvbo/git/link_dl\n",
        "print(BASE_PATH)\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(BASE_PATH)\n",
        "\n",
        "from utils import get_num_cpu_cores\n",
        "\n",
        "def get_fashion_mnist_data():\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
        "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
        "\n",
        "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
        "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
        "    print(\"Sample Data Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "    print(\"Sample Data Target: \", f_mnist_train[0][1])  # 9\n",
        "\n",
        "    num_data_loading_workers = get_num_cpu_cores()\n",
        "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
        "\n",
        "    train_data_loader = DataLoader(\n",
        "        dataset=f_mnist_train, batch_size=wandb.config.batch_size, shuffle=True,\n",
        "        pin_memory=True, num_workers=num_data_loading_workers\n",
        "    )\n",
        "\n",
        "    validation_data_loader = DataLoader(\n",
        "        dataset=f_mnist_validation, batch_size=wandb.config.batch_size,\n",
        "        pin_memory=True, num_workers=num_data_loading_workers\n",
        "    )\n",
        "\n",
        "    f_mnist_transforms = nn.Sequential(\n",
        "        transforms.ConvertImageDtype(torch.float),\n",
        "        transforms.Normalize(mean=0.28626272082328796, std=0.353203684091568),\n",
        "    )\n",
        "\n",
        "    return train_data_loader, validation_data_loader, f_mnist_transforms\n",
        "\n",
        "\n",
        "def get_fashion_mnist_test_data():\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
        "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
        "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "\n",
        "    test_data_loader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test))\n",
        "\n",
        "    f_mnist_transforms = nn.Sequential(\n",
        "        transforms.ConvertImageDtype(torch.float),\n",
        "        transforms.Normalize(mean=0.2868492901325226, std=0.3524441719055176),\n",
        "    )\n",
        "\n",
        "    return f_mnist_test_images, test_data_loader, f_mnist_transforms\n"
      ],
      "metadata": {
        "id": "Jmi6KU4ri7AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fashion_mnist_train_data_1.py\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import wandb\n",
        "from torch import nn\n",
        "\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve().parent)\n",
        "print(BASE_PATH)\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(BASE_PATH)\n",
        "\n",
        "from utils import get_num_cpu_cores\n",
        "\n",
        "def find_fashion_mnist_data_mean_std():\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    f_mnist_train = datasets.FashionMNIST(data_path, train=True, download=True, transform=transforms.ToTensor())\n",
        "    f_mnist_train, f_mnist_validation = random_split(f_mnist_train, [55_000, 5_000])\n",
        "\n",
        "    print(\"Num Train Samples: \", len(f_mnist_train))\n",
        "    print(\"Num Validation Samples: \", len(f_mnist_validation))\n",
        "    print(\"Sample Data Shape: \", f_mnist_train[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "    print(\"Sample Data Target: \", f_mnist_train[0][1])  # 9\n",
        "\n",
        "    num_data_loading_workers = get_num_cpu_cores()\n",
        "    print(\"Number of Data Loading Workers:\", num_data_loading_workers)\n",
        "\n",
        "    print(\"\\nCalculating mean and std for normalization...\")\n",
        "\n",
        "    # 55,000개의 f_mnist_train 데이터 전체를 로드할 DataLoader 생성\n",
        "    # ToTensor()가 적용되어 0~1 사이 값으로 변환된 상태\n",
        "    calculator_loader = DataLoader(\n",
        "        dataset=f_mnist_train,\n",
        "        batch_size=len(f_mnist_train),  # 모든 데이터를 하나의 배치로 로드\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # DataLoader에서 데이터 배치 가져오기\n",
        "    # data의 shape: [55000, 1, 28, 28]\n",
        "    data = next(iter(calculator_loader))[0]\n",
        "\n",
        "    # 전체 픽셀의 평균(mean)과 표준편차(std) 계산\n",
        "    # data.mean() : 55000 * 1 * 28 * 28 개의 모든 픽셀 값의 평균\n",
        "    # data.std()  : 55000 * 1 * 28 * 28 개의 모든 픽셀 값의 표준편차\n",
        "    f_mnist_mean = data.mean().item()\n",
        "    f_mnist_std = data.std().item()\n",
        "\n",
        "    print(f\"Calculated Mean: {f_mnist_mean}\")\n",
        "    print(f\"Calculated Std: {f_mnist_std}\")\n",
        "\n",
        "def find_fashion_mnist_test_data_mean_std():\n",
        "    data_path = os.path.join(BASE_PATH, \"_00_data\", \"j_fashion_mnist\")\n",
        "\n",
        "    # f_mnist_test_images = datasets.FashionMNIST(data_path, train=False, download=True)\n",
        "    f_mnist_test = datasets.FashionMNIST(data_path, train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    print(\"Num Test Samples: \", len(f_mnist_test))\n",
        "    print(\"Sample Shape: \", f_mnist_test[0][0].shape)  # torch.Size([1, 28, 28])\n",
        "\n",
        "\n",
        "    calculator_dataloader = DataLoader(dataset=f_mnist_test, batch_size=len(f_mnist_test), shuffle=False)\n",
        "    data = next(iter(calculator_dataloader))[0]\n",
        "    f_mnist_test_mean = data.mean().item()\n",
        "    f_mnist_test_std = data.std().item()\n",
        "    print(f\"Calculated Mean: {f_mnist_test_mean}\")\n",
        "    print(f\"Calculated Std: {f_mnist_test_std}\")"
      ],
      "metadata": {
        "id": "8JpTWIvpjc-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 코드\n",
        "- `cnn_model_with_dropout` : normalization이 적용되지 않은 모델\n",
        "- `fashion_mnist_train_cnn_with_norm` : batch norm, layer norm이 적용된 모델과 args를 통해 어떤 normalization을 선택할지에 대한 코드"
      ],
      "metadata": {
        "id": "W_4kMgLxjtDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cnn_model_with_dropout.py\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "\n",
        "def get_cnn_model_with_dropout():\n",
        "  class MyModel(nn.Module):\n",
        "    def __init__(self, in_channels, n_output):\n",
        "      super().__init__()\n",
        "\n",
        "      self.model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 16 x 28 x 28 → 64 x 28 x 28\n",
        "        nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # 64 x 28 x 28 → 64 x 14 x 14\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        # 64 x 14 x 14 → 128 x 14 x 14\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        # 128 x 14 x 14 → 128 x 7 x 7\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128*7*7, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128, n_output),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "  my_model = MyModel(in_channels=1, n_output=10)\n",
        "\n",
        "  return my_model"
      ],
      "metadata": {
        "id": "7VgWCE9WkC6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fashion_mnist_train_cnn_with_norm.py\n",
        "\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "from datetime import datetime\n",
        "import os\n",
        "import wandb\n",
        "from pathlib import Path\n",
        "from torchinfo import summary\n",
        "\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve()) # BASE_PATH: /content\n",
        "print(BASE_PATH)\n",
        "import sys\n",
        "sys.path.append(BASE_PATH)\n",
        "\n",
        "CHECKPOINT_FILE_PATH = os.path.join(BASE_PATH, \"checkpoint\")\n",
        "print(CHECKPOINT_FILE_PATH)\n",
        "if not os.path.isdir(CHECKPOINT_FILE_PATH):\n",
        "  os.makedirs(os.path.join(BASE_PATH, \"checkpoint\"))\n",
        "\n",
        "import sys\n",
        "sys.path.append(BASE_PATH)\n",
        "\n",
        "from trainer import ClassificationTrainer\n",
        "from fashion_mnist_train_data import get_fashion_mnist_data\n",
        "from arg_parser import get_parser\n",
        "from cnn_model_with_dropout import get_cnn_model_with_dropout\n",
        "\n",
        "\n",
        "def get_cnn_model_with_dropout_and_batch_normalization():\n",
        "  class MyModel(nn.Module):\n",
        "    def __init__(self, in_channels, n_output):\n",
        "      super().__init__()\n",
        "\n",
        "      self.model = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 16 x 28 x 28 → 64 x 28 x 28\n",
        "        nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        # 64 x 28 x 28 → 64 x 14 x 14\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        # 64 x 14 x 14 → 128 x 14 x 14\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 128 x 14 x 14 → 128 x 7 x 7\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128*7*7, 128),\n",
        "        nn.BatchNorm1d(num_features=128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128, n_output),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "  # 1 * 28 * 28\n",
        "  my_model = MyModel(in_channels=1, n_output=10)\n",
        "\n",
        "  return my_model\n",
        "\n",
        "\n",
        "def get_cnn_model_with_dropout_and_layer_normalization():\n",
        "  class MyModel(nn.Module):\n",
        "    def __init__(self, in_channels, n_output):\n",
        "      super().__init__()\n",
        "\n",
        "      self.model = nn.Sequential(\n",
        "        # 1 x 28 x 28 -> 16 x 28 x 28\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=16, kernel_size=3, padding=1),\n",
        "        nn.LayerNorm(normalized_shape=[16, 28, 28]),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 16 x 28 x 28 → 64 x 28 x 28\n",
        "        nn.Conv2d(in_channels=16, out_channels=64, kernel_size=3, padding=1),\n",
        "        nn.LayerNorm(normalized_shape=[64, 28, 28]),\n",
        "        nn.ReLU(),\n",
        "        # 64 x 28 x 28 → 64 x 14 x 14\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        # 64 x 14 x 14 → 128 x 14 x 14\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "        nn.LayerNorm(normalized_shape=[128, 14, 14]),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        # 128 x 14 x 14 → 128 x 7 x 7\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Dropout(0.25),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128*7*7, 128),\n",
        "        nn.LayerNorm(normalized_shape=[128]),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(128, n_output),\n",
        "      )\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.model(x)\n",
        "      return x\n",
        "\n",
        "  # 1 * 28 * 28\n",
        "  my_model = MyModel(in_channels=1, n_output=10)\n",
        "\n",
        "  return my_model\n",
        "\n",
        "\n",
        "def main(args):\n",
        "  config = {\n",
        "    'epochs': args.epochs,\n",
        "    'batch_size': args.batch_size,\n",
        "    'validation_intervals': args.validation_intervals,\n",
        "    'learning_rate': args.learning_rate,\n",
        "    'early_stop_patience': args.early_stop_patience,\n",
        "    'early_stop_delta': args.early_stop_delta,\n",
        "    'weight_decay': args.weight_decay,\n",
        "    'dropout': args.dropout,\n",
        "    'normalization': args.normalization\n",
        "  }\n",
        "\n",
        "  normalization_names = [\"no_normalization\", \"batch_norm\", \"layer_norm\"]\n",
        "  technique_name = \"{0}\".format(normalization_names[args.normalization])\n",
        "  run_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "  name = \"{0}_{1}\".format(technique_name, run_time_str)\n",
        "\n",
        "  project_name = \"cnn_fashion_mnist_with_normalization\"\n",
        "  wandb.init(\n",
        "    mode=\"online\" if args.wandb else \"disabled\",\n",
        "    project=project_name,\n",
        "    notes=\"fashion mnist experiment with cnn and normalization\",\n",
        "    tags=[\"cnn\", \"fashion mnist\", \"normalization\"],\n",
        "    name=name,\n",
        "    config=config\n",
        "  )\n",
        "  print(args)\n",
        "  print(wandb.config)\n",
        "\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(f\"Training on device {device}.\")\n",
        "\n",
        "  train_data_loader, validation_data_loader, cifar10_transforms = get_fashion_mnist_data()\n",
        "\n",
        "  if args.normalization == 0:\n",
        "    model = get_cnn_model_with_dropout()\n",
        "  elif args.normalization == 1:\n",
        "    model = get_cnn_model_with_dropout_and_batch_normalization()\n",
        "  elif args.normalization == 2:\n",
        "    model = get_cnn_model_with_dropout_and_layer_normalization()\n",
        "  else:\n",
        "    raise ValueError()\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  # torchinfo 모델 구조 출력\n",
        "  print(\"=\" * 80)\n",
        "  print(f\"Model Structure (Normalization: {args.normalization})\")\n",
        "  summary(\n",
        "      model,\n",
        "      input_size=(args.batch_size, 1, 28, 28),\n",
        "      col_names=[\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"],\n",
        "      verbose=1  # 0: 간단한 요약, 1: 상세 요약\n",
        "  )\n",
        "  print(\"=\" * 80)\n",
        "\n",
        "  optimizers = [\n",
        "    optim.SGD(model.parameters(), lr=wandb.config.learning_rate, weight_decay=args.weight_decay),\n",
        "    optim.SGD(model.parameters(), lr=wandb.config.learning_rate, momentum=0.9, weight_decay=args.weight_decay),\n",
        "    optim.RMSprop(model.parameters(), lr=wandb.config.learning_rate, weight_decay=args.weight_decay),\n",
        "    optim.Adam(model.parameters(), lr=wandb.config.learning_rate, weight_decay=args.weight_decay)\n",
        "  ]\n",
        "\n",
        "  print(\"Optimizer:\", optimizers[args.optimizer])\n",
        "\n",
        "  classification_trainer = ClassificationTrainer(\n",
        "    project_name, model, optimizers[args.optimizer],\n",
        "    train_data_loader, validation_data_loader, cifar10_transforms,\n",
        "    run_time_str, wandb, device, CHECKPOINT_FILE_PATH\n",
        "  )\n",
        "  classification_trainer.train_loop()\n",
        "\n",
        "  wandb.finish()\n"
      ],
      "metadata": {
        "id": "HUEe9GMgkKm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 수행 코드\n",
        "- `fashion_mnist_test`"
      ],
      "metadata": {
        "id": "FQUrH_ZIkZ8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fashion_mnist_test.py\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "import sys\n",
        "import wandb\n",
        "\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve())  # /content\n",
        "sys.path.append(BASE_PATH)\n",
        "print(f\"Base Path: {BASE_PATH}\")\n",
        "CHECKPOINT_FILE_PATH = os.path.join(BASE_PATH, \"checkpoint\")\n",
        "\n",
        "from fashion_mnist_train_data import get_fashion_mnist_test_data\n",
        "from cnn_model_with_dropout import get_cnn_model_with_dropout\n",
        "from fashion_mnist_train_cnn_with_norm import (\n",
        "    get_cnn_model_with_dropout_and_batch_normalization,\n",
        "    get_cnn_model_with_dropout_and_layer_normalization\n",
        ")\n",
        "\n",
        "def get_test_parser():\n",
        "    \"\"\"테스트 스크립트용 Arg Parser\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Test trained Fashion MNIST model\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-n\", \"--normalization\", type=int, required=True,\n",
        "        help=\"훈련 시 사용한 정규화 타입 (0: None, 1: BatchNorm, 2: LayerNorm)\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-c\", \"--checkpoint\", type=str, required=True,\n",
        "        help=\"불러올 학습된 모델의 체크포인트 파일 경로 (.pt 파일)\"\n",
        "    )\n",
        "    return parser\n",
        "\n",
        "def test_model(model, test_data_loader, transforms, device):\n",
        "    \"\"\"테스트 데이터로 모델을 평가하고 정확도를 반환\"\"\"\n",
        "\n",
        "    model.eval()  # 모델 평가 모드로 설정 (Dropout, BatchNorm 비활성화)\n",
        "    model.to(device)\n",
        "\n",
        "    num_corrects_test = 0\n",
        "    num_test_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_batch in test_data_loader:\n",
        "            input_test, target_test = test_batch\n",
        "            input_test = input_test.to(device=device)\n",
        "            target_test = target_test.to(device=device)\n",
        "\n",
        "            # 데이터 정규화 적용\n",
        "            if transforms:\n",
        "                input_test = transforms(input_test)\n",
        "\n",
        "            # 예측\n",
        "            output_test = model(input_test)\n",
        "\n",
        "            # 정확도 계산\n",
        "            predicted_test = torch.argmax(output_test, dim=1)\n",
        "            num_corrects_test += torch.sum(torch.eq(predicted_test, target_test)).item()\n",
        "            num_test_samples += len(input_test)\n",
        "\n",
        "    # 최종 정확도 계산\n",
        "    test_accuracy = 100.0 * num_corrects_test / num_test_samples\n",
        "    return test_accuracy\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = get_test_parser()\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # fashion_mnist_train_data.py가 wandb.config를 참조할 가능성에 대비\n",
        "    # (get_fashion_mnist_test_data는 사용하지 않지만 안전을 위해)\n",
        "    config = {'batch_size': 1024}  # 테스트 로더는 이 값을 사용하지 않습니다.\n",
        "    wandb.init(mode=\"disabled\", config=config)\n",
        "\n",
        "    # 1. 테스트 데이터 로드\n",
        "    _, test_data_loader, test_transforms = get_fashion_mnist_test_data()\n",
        "    print(f\"Loaded {len(test_data_loader.dataset)} test samples.\")\n",
        "\n",
        "    # 2. 훈련 시 사용한 모델 아키텍처 생성\n",
        "    if args.normalization == 0:\n",
        "        model = get_cnn_model_with_dropout()\n",
        "        norm_name = \"No Normalization\"\n",
        "    elif args.normalization == 1:\n",
        "        model = get_cnn_model_with_dropout_and_batch_normalization()\n",
        "        norm_name = \"Batch Normalization\"\n",
        "    elif args.normalization == 2:\n",
        "        model = get_cnn_model_with_dropout_and_layer_normalization()\n",
        "        norm_name = \"Layer Normalization\"\n",
        "    else:\n",
        "        raise ValueError(\"Invalid normalization type. Must be 0, 1, or 2.\")\n",
        "    print(f\"Instantiated model structure with: {norm_name}\")\n",
        "\n",
        "    # 3. 훈련된 가중치(State Dictionary) 불러오기\n",
        "    checkpoint_path = os.path.join(CHECKPOINT_FILE_PATH, args.checkpoint)\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(f\"Error: Checkpoint file not found at {args.checkpoint}\")\n",
        "        print(checkpoint_path)\n",
        "        return\n",
        "\n",
        "    # map_location을 통해 CPU/GPU 환경에 맞게 로드\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
        "    print(f\"Successfully loaded trained weights from: {args.checkpoint}\")\n",
        "\n",
        "    # 4. 테스트 실행\n",
        "    test_accuracy = test_model(model, test_data_loader, test_transforms, device)\n",
        "\n",
        "    # 5. 결과 출력\n",
        "    print(\"\\n\" + \"=\" * 40)\n",
        "    print(f\"  Model: {norm_name} ({args.checkpoint})\")\n",
        "    print(f\"  Test Accuracy: {test_accuracy:.4f}%\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ydHf-XrPkeJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 랜덤 10개 데이터 예측 및 출력 코드"
      ],
      "metadata": {
        "id": "3esbt1cckl03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# predict_sample.py\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import sys\n",
        "import argparse\n",
        "import random\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import wandb\n",
        "\n",
        "# 경로 설정 (기존 스크립트와 동일)\n",
        "BASE_PATH = str(Path(os.getcwd()).resolve())  # /content\n",
        "sys.path.append(BASE_PATH)\n",
        "print(f\"Base Path: {BASE_PATH}\")\n",
        "\n",
        "# 필요한 함수 및 모델 클래스 임포트\n",
        "from fashion_mnist_train_data import get_fashion_mnist_test_data\n",
        "from cnn_model_with_dropout import get_cnn_model_with_dropout\n",
        "from fashion_mnist_train_cnn_with_norm import (\n",
        "    get_cnn_model_with_dropout_and_batch_normalization,\n",
        "    get_cnn_model_with_dropout_and_layer_normalization\n",
        ")\n",
        "\n",
        "# Fashion MNIST 레이블 이름\n",
        "FASHION_MNIST_LABELS = (\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
        ")\n",
        "\n",
        "\n",
        "def get_predict_parser():\n",
        "    \"\"\"예측 스크립트용 Argument Parser\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Predict 10 random samples from Fashion MNIST\")\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-n\", \"--normalization\", type=int, required=True,\n",
        "        help=\"훈련 시 사용한 정규화 타입 (0: None, 1: BatchNorm, 2: LayerNorm)\"\n",
        "    )\n",
        "\n",
        "    parser.add_argument(\n",
        "        \"-c\", \"--checkpoint\", type=str, required=True,\n",
        "        help=\"불러올 학습된 모델의 체크포인트 파일 경로 (.pt 파일)\"\n",
        "    )\n",
        "    return parser\n",
        "\n",
        "\n",
        "def main():\n",
        "    parser = get_predict_parser()\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    config = {'batch_size': 32}\n",
        "    wandb.init(mode=\"disabled\", config=config)\n",
        "\n",
        "    # 1. 테스트 데이터 로드 (f_mnist_test_images 사용)\n",
        "    print(\"Loading test data...\")\n",
        "    f_mnist_test_images, _, test_transforms = get_fashion_mnist_test_data()\n",
        "\n",
        "    # 모델 입력용: 이미지를 텐서로 변환하는 변환기\n",
        "    to_tensor_transform = transforms.ToTensor()\n",
        "\n",
        "    # 2. 훈련 시 사용한 모델 아키텍처 생성\n",
        "    norm_names = [\"No Normalization\", \"Batch Normalization\", \"Layer Normalization\"]\n",
        "    try:\n",
        "        norm_name = norm_names[args.normalization]\n",
        "    except IndexError:\n",
        "        raise ValueError(\"Invalid normalization type. Must be 0, 1, or 2.\")\n",
        "\n",
        "    print(f\"Loading model structure with: {norm_name}\")\n",
        "    if args.normalization == 0:\n",
        "        model = get_cnn_model_with_dropout()\n",
        "    elif args.normalization == 1:\n",
        "        model = get_cnn_model_with_dropout_and_batch_normalization()\n",
        "    else:  # args.normalization == 2\n",
        "        model = get_cnn_model_with_dropout_and_layer_normalization()\n",
        "\n",
        "    # 3. 훈련된 가중치 불러오기\n",
        "    if not os.path.exists(args.checkpoint):\n",
        "        print(f\"Error: Checkpoint file not found at {args.checkpoint}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Loading weights from {args.checkpoint}...\")\n",
        "    model.load_state_dict(torch.load(args.checkpoint, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()  # 모델을 평가 모드로 설정\n",
        "\n",
        "    # 4. 10개의 무작위 샘플 인덱스 선택\n",
        "    num_samples = 10\n",
        "    indices = random.sample(range(len(f_mnist_test_images)), num_samples)\n",
        "    print(f\"Running predictions on {num_samples} random images...\")\n",
        "\n",
        "    # 5. 예측 및 시각화\n",
        "    plt.figure(figsize=(15, 8))  # 2행 5열의 이미지를 표시하기에 적절한 크기\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # 1. 원본 이미지와 실제 레이블 가져오기\n",
        "        image_pil, true_label_int = f_mnist_test_images[idx]\n",
        "        true_label_str = FASHION_MNIST_LABELS[true_label_int]\n",
        "\n",
        "        # 2. 이미지를 모델 입력에 맞게 변환\n",
        "        img_tensor = to_tensor_transform(image_pil).to(device)\n",
        "        img_normalized = test_transforms(img_tensor)\n",
        "        img_batch = img_normalized.unsqueeze(0)  # [1, 1, 28, 28]\n",
        "\n",
        "        # 3. 모델 예측\n",
        "        with torch.no_grad():\n",
        "            output = model(img_batch)\n",
        "            pred_label_int = torch.argmax(output, dim=1).item()\n",
        "            pred_label_str = FASHION_MNIST_LABELS[pred_label_int]\n",
        "\n",
        "        # 4. 결과 비교\n",
        "        is_correct = (true_label_int == pred_label_int)\n",
        "        result_str = \"Correct\" if is_correct else \"Incorrect\"\n",
        "        title_color = 'green' if is_correct else 'red'\n",
        "\n",
        "        # 5. 서브플롯에 결과 표시\n",
        "        ax = plt.subplot(2, 5, i + 1)\n",
        "        ax.imshow(image_pil, cmap='gray')\n",
        "        ax.set_title(\n",
        "            f\"True: {true_label_str}\\nPred: {pred_label_str}\\n{result_str}\",\n",
        "            color=title_color,\n",
        "            fontsize=10\n",
        "        )\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(\"Model Predictions (10 Random Samples)\", fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # 메인 타이틀과 겹치지 않게 조정\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "L_pU4A5HkudX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## arg_parser, early_stopping, trainer, utils"
      ],
      "metadata": {
        "id": "yvfPXMihlLpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# arg_parser.py\n",
        "\n",
        "import argparse\n",
        "\n",
        "def get_parser():\n",
        "  parser = argparse.ArgumentParser()\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"--wandb\", action=argparse.BooleanOptionalAction, default=False, help=\"Wandb: True or False\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-b\", \"--batch_size\", type=int, default=2_048, help=\"Batch size (int, default: 2_048)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-e\", \"--epochs\", type=int, default=50, help=\"Number of training epochs (int, default:10_000)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-r\", \"--learning_rate\", type=float, default=1e-3, help=\"Learning rate (float, default: 1e-3)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-v\", \"--validation_intervals\", type=int, default=10,\n",
        "    help=\"Number of training epochs between validations (int, default: 10)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-p\", \"--early_stop_patience\", type=int, default=10,\n",
        "    help=\"Number of early stop patience (int, default: 10)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-d\", \"--early_stop_delta\", type=float, default=0.00001,\n",
        "    help=\"Delta value of early stop (float, default: 0.00001)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-o\", \"--optimizer\", type=int, default=0,\n",
        "    help=\"Optimizers (0: SGD, 1: Momentum, 2: RMSProp, 3: Adam, default: 0)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-w\", \"--weight_decay\", type=float, default=0.0, help=\"Weight decay (float, default: 0.0)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"--dropout\", action=argparse.BooleanOptionalAction, default=False, help=\"Dropout: True or False\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"-n\", \"--normalization\", type=int, default=0,\n",
        "    help=\"Normalization (0: No Normalization, 1: BatchNorm, 2: LayerNorm, default: 0)\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "    \"--augment\", action=argparse.BooleanOptionalAction, default=False, help=\"Image Augment: True or False\"\n",
        "  )\n",
        "\n",
        "  return parser"
      ],
      "metadata": {
        "id": "SVIVnO6XlWnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# early_stopping.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "  \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "  def __init__(self, patience=10, delta=0.00001, project_name=None, checkpoint_file_path=None, run_time_str=None):\n",
        "    self.patience = patience\n",
        "    self.counter = 0\n",
        "    self.delta = delta\n",
        "\n",
        "    self.val_loss_min = None\n",
        "    self.file_path = os.path.join(\n",
        "      checkpoint_file_path, f\"{project_name}_checkpoint_{run_time_str}.pt\"\n",
        "    )\n",
        "    self.latest_file_path = os.path.join(\n",
        "      checkpoint_file_path, f\"{project_name}_checkpoint_latest.pt\"\n",
        "    )\n",
        "\n",
        "  def check_and_save(self, new_validation_loss, model):\n",
        "    early_stop = False\n",
        "\n",
        "    if self.val_loss_min is None:\n",
        "      self.val_loss_min = new_validation_loss\n",
        "      message = f'Early stopping is stated!'\n",
        "    elif new_validation_loss < self.val_loss_min - self.delta:\n",
        "      message = f'V_loss decreased ({self.val_loss_min:7.5f} --> {new_validation_loss:7.5f}). Saving model...'\n",
        "      self.save_checkpoint(new_validation_loss, model)\n",
        "      self.val_loss_min = new_validation_loss\n",
        "      self.counter = 0\n",
        "    else:\n",
        "      self.counter += 1\n",
        "      message = f'Early stopping counter: {self.counter} out of {self.patience}'\n",
        "      if self.counter >= self.patience:\n",
        "        early_stop = True\n",
        "        message += \" *** TRAIN EARLY STOPPED! ***\"\n",
        "\n",
        "    return message, early_stop\n",
        "\n",
        "  def save_checkpoint(self, val_loss, model):\n",
        "    '''Saves model when validation loss decrease.'''\n",
        "    torch.save(model.state_dict(), self.file_path)\n",
        "    torch.save(model.state_dict(), self.latest_file_path)\n",
        "    self.val_loss_min = val_loss"
      ],
      "metadata": {
        "id": "dGtdp9HNlb1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainer.py\n",
        "from datetime import datetime\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "from early_stopping import EarlyStopping\n",
        "from utils import strfdelta\n",
        "\n",
        "\n",
        "class ClassificationTrainer:\n",
        "  def __init__(\n",
        "    self, project_name, model, optimizer, train_data_loader, validation_data_loader, transforms,\n",
        "    run_time_str, wandb, device, checkpoint_file_path\n",
        "  ):\n",
        "    self.project_name = project_name\n",
        "    self.model = model\n",
        "    self.optimizer = optimizer\n",
        "    self.train_data_loader = train_data_loader\n",
        "    self.validation_data_loader = validation_data_loader\n",
        "    self.transforms = transforms\n",
        "    self.run_time_str = run_time_str\n",
        "    self.wandb = wandb\n",
        "    self.device = device\n",
        "    self.checkpoint_file_path = checkpoint_file_path\n",
        "\n",
        "    # Use a built-in loss function\n",
        "    self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "  def do_train(self):\n",
        "    self.model.train()  # Will be explained at 'Diverse Techniques' section\n",
        "\n",
        "    loss_train = 0.0\n",
        "    num_corrects_train = 0\n",
        "    num_trained_samples = 0\n",
        "    num_trains = 0\n",
        "\n",
        "    for train_batch in self.train_data_loader:\n",
        "      # input_train.shape: torch.Size([2048, 3, 32, 32]),  target_train.shape: torch.Size([2048])\n",
        "      input_train, target_train = train_batch\n",
        "      input_train = input_train.to(device=self.device)\n",
        "      target_train = target_train.to(device=self.device)\n",
        "\n",
        "      if self.transforms:\n",
        "        input_train = self.transforms(input_train)\n",
        "\n",
        "      output_train = self.model(input_train)\n",
        "      loss = self.loss_fn(output_train, target_train)\n",
        "      loss_train += loss.item()\n",
        "\n",
        "      predicted_train = torch.argmax(output_train, dim=-1)\n",
        "\n",
        "      # >>> predicted_train: tensor([5, 8, 9, 0, 9, 8, 9, 8, ..., 0, 1, 3, 7, 1, 4, 3])\n",
        "      # >>> target_train:    tensor([5, 8, 9, 2, 9, 8, 7, 8, ..., 4, 1, 9, 6, 1, 4, 3])\n",
        "      num_corrects_train += torch.sum(torch.eq(predicted_train, target_train)).item()\n",
        "\n",
        "      num_trained_samples += len(input_train)\n",
        "      num_trains += 1\n",
        "\n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "    train_loss = loss_train / num_trains\n",
        "    train_accuracy = 100.0 * num_corrects_train / num_trained_samples\n",
        "\n",
        "    return train_loss, train_accuracy\n",
        "\n",
        "  def do_validation(self):\n",
        "    self.model.eval()   # Explained at 'Diverse Techniques' section\n",
        "\n",
        "    loss_validation = 0.0\n",
        "    num_corrects_validation = 0\n",
        "    num_validated_samples = 0\n",
        "    num_validations = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for validation_batch in self.validation_data_loader:\n",
        "        input_validation, target_validation = validation_batch\n",
        "        input_validation = input_validation.to(device=self.device)\n",
        "        target_validation = target_validation.to(device=self.device)\n",
        "\n",
        "        if self.transforms:\n",
        "          input_validation = self.transforms(input_validation)\n",
        "\n",
        "        output_validation = self.model(input_validation)\n",
        "        loss_validation += self.loss_fn(output_validation, target_validation).item()\n",
        "\n",
        "        predicted_validation = torch.argmax(output_validation, dim=1)\n",
        "        num_corrects_validation += torch.sum(torch.eq(predicted_validation, target_validation)).item()\n",
        "\n",
        "        num_validated_samples += len(input_validation)\n",
        "        num_validations += 1\n",
        "\n",
        "    validation_loss = loss_validation / num_validations\n",
        "    validation_accuracy = 100.0 * num_corrects_validation / num_validated_samples\n",
        "\n",
        "    return validation_loss, validation_accuracy\n",
        "\n",
        "  def train_loop(self):\n",
        "    early_stopping = EarlyStopping(\n",
        "      patience=self.wandb.config.early_stop_patience,\n",
        "      delta=self.wandb.config.early_stop_delta,\n",
        "      project_name=self.project_name,\n",
        "      checkpoint_file_path=self.checkpoint_file_path,\n",
        "      run_time_str=self.run_time_str\n",
        "    )\n",
        "    n_epochs = self.wandb.config.epochs\n",
        "    training_start_time = datetime.now()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "      train_loss, train_accuracy = self.do_train()\n",
        "\n",
        "      if epoch == 1 or epoch % self.wandb.config.validation_intervals == 0:\n",
        "        validation_loss, validation_accuracy = self.do_validation()\n",
        "\n",
        "        elapsed_time = datetime.now() - training_start_time\n",
        "        epoch_per_second = 0 if elapsed_time.seconds == 0 else epoch / elapsed_time.seconds\n",
        "\n",
        "        message, early_stop = early_stopping.check_and_save(validation_loss, self.model)\n",
        "\n",
        "        print(\n",
        "          f\"[Epoch {epoch:>3}] \"\n",
        "          f\"T_loss: {train_loss:7.5f}, \"\n",
        "          f\"T_accuracy: {train_accuracy:6.4f} | \"\n",
        "          f\"V_loss: {validation_loss:7.5f}, \"\n",
        "          f\"V_accuracy: {validation_accuracy:6.4f} | \"\n",
        "          f\"{message} | \"\n",
        "          f\"T_time: {strfdelta(elapsed_time, '%H:%M:%S')}, \"\n",
        "          f\"T_speed: {epoch_per_second:4.3f}\"\n",
        "        )\n",
        "\n",
        "        self.wandb.log({\n",
        "          \"Epoch\": epoch,\n",
        "          \"Training loss\": train_loss,\n",
        "          \"Training accuracy (%)\": train_accuracy,\n",
        "          \"Validation loss\": validation_loss,\n",
        "          \"Validation accuracy (%)\": validation_accuracy,\n",
        "          \"Training speed (epochs/sec.)\": epoch_per_second,\n",
        "        })\n",
        "\n",
        "        if early_stop:\n",
        "          break\n",
        "\n",
        "    elapsed_time = datetime.now() - training_start_time\n",
        "    print(f\"Final training time: {strfdelta(elapsed_time, '%H:%M:%S')}\")\n"
      ],
      "metadata": {
        "id": "mtaQXz5sliSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def is_linux():\n",
        "    if sys.platform.startswith(\"linux\"):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_windows():\n",
        "    if os.name == \"nt\":\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def is_mac():\n",
        "    if sys.platform == \"darwin\":\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "\n",
        "def get_num_cpu_cores():\n",
        "    import multiprocessing\n",
        "    return multiprocessing.cpu_count()\n",
        "\n",
        "\n",
        "from string import Template\n",
        "\n",
        "class DeltaTemplate(Template):\n",
        "    delimiter = \"%\"\n",
        "\n",
        "    def strfdelta(tdelta, fmt):\n",
        "        d = {\"D\": tdelta.days}\n",
        "        d[\"H\"], rem = divmod(tdelta.seconds, 3600)\n",
        "        d[\"M\"], d[\"S\"] = divmod(rem, 60)\n",
        "        t = DeltaTemplate(fmt)\n",
        "        return t.substitute(**d)\n",
        "\n",
        "\n",
        "def strfdelta(td, fmt):\n",
        "\n",
        "    # Get the timedelta’s sign and absolute number of seconds.\n",
        "    sign = \"-\" if td.days < 0 else \"+\"\n",
        "    secs = abs(td).total_seconds()\n",
        "\n",
        "    # Break the seconds into more readable quantities.\n",
        "    days, rem = divmod(secs, 86400)  # Seconds per day: 24 * 60 * 60\n",
        "    hours, rem = divmod(rem, 3600)  # Seconds per hour: 60 * 60\n",
        "    mins, secs = divmod(rem, 60)\n",
        "\n",
        "    # Format (as per above answers) and return the result string.\n",
        "    t = DeltaTemplate(fmt)\n",
        "    return t.substitute(\n",
        "        s=sign,\n",
        "        D=\"{:d}\".format(int(days)),\n",
        "        H=\"{:02d}\".format(int(hours)),\n",
        "        M=\"{:02d}\".format(int(mins)),\n",
        "        S=\"{:02d}\".format(int(secs)),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "tJE7NjndlpE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 숙제 후기\n",
        "지난번 homework2에서는 로컬 환경에서 작업해도 문제가 없었기에 pytorch에서 작업하면 되었다.\n",
        "\n",
        "하지만 본 숙제에서 colab이나 학교 백엔드 서비스를 이용하면서 코드와 데이터를 어떻게 불러오고 실행해야 할 지 알지 못해 막막했다. pytorch에 익숙해질 때쯤에 colab과 학교 백엔드를 사용해보면서 과제를 수행하려니 기능들을 잘 몰라 좀 해메었다.\n",
        "\n",
        "그리고 학습을 시키며 대기하고, 성능이 나오지 않을 경우 코드를 수정하거나 하이퍼파라미터를 바꿔 작업한 뒤 다시 학습을 시키는 일련의 과정이 매우 오래 걸렸고 지치는 느낌이 들었다.\n",
        "\n",
        "homework2에서는 어느정도 이상으로 성능을 끌어올리라는 과제 조건이 없어 모델 구조를 바꾸지 않아도 되었지만, 이번에는 모델 구조를 직접 바꿔보면서 Shape이 안 맞아 고생하기도 하고, 바꿔도 94%를 넘기지 못해 다시 짜는 등의 수고가 생각보다 많았다.\n",
        "모델 구조를 바꾸는데 AI의 도움을 받기도 했다.\n",
        "\n",
        "쉽지는 않았지만 끝내서 다행이라는 생각이 든다."
      ],
      "metadata": {
        "id": "0rFL5jL1XJip"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}